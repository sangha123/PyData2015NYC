{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import cPickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decodeArray(text):\n",
    "    try:\n",
    "        return text.decode('utf-8','replace')\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the jsonfile \n",
    "import simplejson as json\n",
    "f =open(\"reviews_Grocery_and_Gourmet_Food.json\",mode='r')\n",
    "L = f.readlines()\n",
    "f.close()\n",
    "review_list = []\n",
    "rating = []\n",
    "reviewer_id = []\n",
    "product_id = []\n",
    "for l in L:\n",
    "    jj = json.loads(l)\n",
    "    if (len(jj['reviewText'].split(\" \"))>12):\n",
    "        review_list += [jj['reviewText']]\n",
    "        rating += [jj['overall']]\n",
    "        reviewer_id += [jj['reviewerID']]\n",
    "        product_id += [jj['asin']]\n",
    "        \n",
    "\n",
    "d={}\n",
    "d['TEXT'] = review_list\n",
    "d['RATING'] = rating\n",
    "d['reviewerID'] = reviewer_id\n",
    "d['product_id'] = product_id\n",
    "\n",
    "revdf = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(revdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"rev_data_small.csv\", sep='\\t')\n",
    "data = data[len(data.REVIEWTEXT) >12]\n",
    "\n",
    "data[(data.FOOD>4) )].count()\n",
    "data[data.FOOD<3].count()\n",
    "data[data.FOOD<3].REVIEWTEXT\n",
    "good_reviews = data[(data.FOOD>4) ]\n",
    "good_reviews = good_reviews.reset_index().ix[0:100000]\n",
    "\n",
    "\n",
    "bad_reviews = data[(data.FOOD<3)]\n",
    "bad_reviews = bad_reviews.reset_index().ix[0:100000]\n",
    "\n",
    "good_reviews['target'] = 1\n",
    "bad_reviews['target'] = 0\n",
    "all_reviews = good_reviews.append(bad_food_reviews)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hyper Parameter search code:\n",
    "\n",
    "<pre><code>\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.9, 1.0),\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__penalty': ('l2', 'l1')\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "all_reviews = pd.read_csv('Train_rev.csv')\n",
    "\n",
    "def decodeArray(text):\n",
    "    try:\n",
    "        return text.decode('utf-8','replace')\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "X = all_reviews.TEXT.apply(decodeArray).values\n",
    "y = all_reviews.target.values\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=2)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    print(grid_search.best_estimator_.predict_proba([\"the food was amazing\"]))\n",
    "    print(grid_search.best_estimator_.predict_proba([\"the food was delicious\"]))\n",
    "    print(grid_search.best_estimator_.predict_proba([\"the food was not delicious at all\"]))\n",
    "    \n",
    " \n",
    " \n",
    "</code></pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this was the result of hyperparameter search:\n",
    "\n",
    "* Best score: 0.931    \n",
    "* Best parameters set:\n",
    "- clf__penalty: 'l1'\n",
    "- vect__max_df: 0.9\n",
    "- vect__ngram_range: (1, 2)\n",
    "- vect__stop_words: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decodeArray(text):\n",
    "    try:\n",
    "        return text.decode('utf-8','replace')\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR_Vectorizer=TfidfVectorizer(analyzer='word', binary=False,decode_error='strict',\n",
    "                       encoding='utf-8',lowercase=True,\n",
    "                       max_df=0.9,max_features=None,min_df=1,ngram_range=(1, 2),norm='l1',\n",
    "                       preprocessor=None,smooth_idf=False,stop_words=None,strip_accents=None,\n",
    "                       sublinear_tf=False,token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',tokenizer=None,use_idf=False,vocabulary=None)\n",
    "\n",
    "LR_clf=linear_model.LogisticRegression(penalty='l1')\n",
    "LR_pipeline=Pipeline([('vect', LR_Vectorizer),('clf', LR_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_food_reviews = pd.read_csv('Train_rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = all_food_reviews['TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = all_food_reviews['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89168596,  0.88843879,  0.88699203])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LR_pipeline, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding='utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l1', preprocessor=None, smooth_idf=False,\n",
       " ...',\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00433934,  0.99566066]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.predict_proba([\"This chili powder adds a wonderful spiciness and smokiness to dishes. \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34965657,  0.65034343]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.predict_proba([\"Warning, however. Ghost peppers have a spiciness that increases after the first taste, so adjust accordingly.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76197423,  0.23802577]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.predict_proba([\"No sugar, no GMO garbage, no fillers that come with store bought extracts.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00383323,  0.99616677]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.predict_proba([\"This stuff is just amazing.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15018488,  0.84981512]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.predict_proba([\"I use it in everything from baking to cooking and even as suggested in my coffee which is saying a lot because I normally do not care for flavored coffee!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05746628,  0.94253372]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.predict_proba([\"You cannot go wrong with this.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3975833,  0.6024167]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.predict_proba([\"I've ordered from this merchant before, customer satisfaction is their priority and service was quick, shipped right out with tracking even! I'll be buying from GLS Goods again!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07592438,  0.92407562]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pipeline.predict_proba([\"I won't use any other vanilla!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
