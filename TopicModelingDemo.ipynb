{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all of the data and format it for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "f =open(\"../reviews_Grocery_and_Gourmet_Food.json\",mode='r')\n",
    "L = f.readlines()\n",
    "review_list=[]\n",
    "product_id = []\n",
    "d=defaultdict(list)\n",
    "review_dict_list=[]\n",
    "c=0\n",
    "for l in L:\n",
    "    dd={}\n",
    "    jj = json.loads(l)\n",
    "    product_id+=[jj['asin']]\n",
    "    #if jj[\"asin\"] == \"B00LQWKDBM\":\n",
    "    d[jj['asin']].append(jj['reviewText'])\n",
    "    if (len(jj['reviewText'].split(\" \"))>12):\n",
    "        review_list += [jj['reviewText']] \n",
    "    \n",
    "    dd[\"item_id\"] = str(c)\n",
    "    dd[\"content\"] = str(jj['reviewText'])\n",
    "    c+=1\n",
    "    dd_json=json.dumps(dd)\n",
    "    review_dict_list+=[dd_json]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text preprocessing\n",
    "import re\n",
    "\n",
    "def removePunctuation(text):\n",
    "    text=text.lower().strip()\n",
    "    text=re.sub(\"[^0-9a-zA-Z ]\", \"\", text)\n",
    "    return text \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy\n",
    "import scipy as sp\n",
    "import re\n",
    "\n",
    "import urllib2\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk.stem\n",
    "from sklearn import decomposition\n",
    "import unicodedata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling with Non-negative Matrix Factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global english_stemmer \n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "class TopicAnalysis(object):\n",
    "    def Vectorize(self,overviewlist):\n",
    "        \n",
    "        self.vectorizer = TfidfVectorizer(min_df=18, max_df=1.0,stop_words = 'english')\n",
    "        self.vectorized = self.vectorizer.fit_transform(overviewlist)\n",
    "\n",
    "\n",
    "    def NMF(self):\n",
    "\n",
    "        n_topics = 30\n",
    "        n_top_words = 20\n",
    "        self.nmf = decomposition.NMF(n_components=n_topics).fit(self.vectorized)\n",
    "\n",
    "        self.feature_names = self.vectorizer.get_feature_names()\n",
    "\n",
    "        self.topic=[]\n",
    "        self.topic_weight=[]\n",
    "        for topic_idx, topic in enumerate(self.nmf.components_):\n",
    "\n",
    "            self.topic+=[ \" \".join([self.feature_names[i] \\\n",
    "                                    for i in topic.argsort()[:-n_top_words - 1:-1]])\t]\n",
    "            self.topic_weight+=[[topic[i] for i in topic.argsort()[:-n_top_words - 1:-1]]]\n",
    "        self.weight_mat=self.nmf.fit_transform(self.vectorized)\n",
    "\n",
    "        self.topic_id=[]\n",
    "        for i in xrange(len(self.weight_mat)):\n",
    "            idx=numpy.argsort(self.weight_mat[i])\n",
    "            self.topic_id+=[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TT = TopicAnalysis()\n",
    "TT.Vectorize(review_list[0:10000])\n",
    "TT.NMF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"No sugar, no GMO garbage, no fillers that come with store bought extracts. This stuff is just amazing. I use it in everything from baking to cooking and even as suggested in my coffee which is saying a lot because I normally do not care for flavored coffee! You cannot go wrong with this. I've ordered from this merchant before, customer satisfaction is their priority and service was quick, shipped right out with tracking even! I'll be buying from GLS Goods again! I won't use any other vanilla!\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[set(),\n",
       " set(),\n",
       " {u'quick', u'service'},\n",
       " {u'coffee'},\n",
       " {u'cooking'},\n",
       " {u'sugar'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {u'amazing', u'just', u'right'},\n",
       " set(),\n",
       " {u'amazing', u'vanilla'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {u'bought'},\n",
       " {u'lot'},\n",
       " set(),\n",
       " {u'cooking'},\n",
       " {u'amazing', u'buying'},\n",
       " {u'stuff'},\n",
       " {u'bought', u'buying', u'store'},\n",
       " {u'bought'},\n",
       " {u'ordered'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {u'use'},\n",
       " {u'care'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x:set(removePunctuation(review_list[0]).lower().split(\" \")).intersection(set(x.split(\" \")).intersection()),TT.topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'This chili powder adds a wonderful spiciness and smokiness to dishes.  Warning, however. Ghost peppers have a spiciness that increases after the first taste, so adjust accordingly.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'chili', u'ghost'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {u'wonderful'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {u'taste', u'wonderful'},\n",
       " {u'adds', u'wonderful'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {u'chili'},\n",
       " set(),\n",
       " {u'chili', u'ghost', u'peppers'},\n",
       " {u'wonderful'},\n",
       " {u'wonderful'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {u'dishes'},\n",
       " set()]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x:set(removePunctuation(review_list[25]).lower().split(\" \")).intersection(set(x.split(\" \")).intersection()),TT.topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'hot sauces heat kick hotter pepper drops drop chili wings food burn mustard super habanero dave ghost salsa flavorful insanity',\n",
       " u'tea green teas tazo black earl drink bags grey loose cup blend strong orange bag harney iced leaves drinking jasmine',\n",
       " u'great price tastes tasting fast snack works makes quick little service day value work job worked way shape goes deal',\n",
       " u'coffee cup maker water make filter pot drip drink chicory grounds beans blue mountain morning brew pour ground french cafix',\n",
       " u'good pretty quality price value deal tastes bit expected fresh thing little quite looking nice job mix cooking fan easy',\n",
       " u'sugar syrup free maple joseph cookies real tastes maltitol low pancakes carb syrups formula corn diabetic mix does tasting diet',\n",
       " u'cheese cheeses blue cheddar goat wonderful aged wine crackers creamy igourmet bread milk texture sharp assortment excellent soft mild pound',\n",
       " u'product excellent purchase quality used purchased shipping hard exactly products food company thanks received licorice item happy works future money',\n",
       " u'best ve tried years used far try brands brand tasted ago using licorice ll different family market chai formula teas',\n",
       " u'just right don bit little eat want got maybe bag wish heat make know need work water ll homemade amazing',\n",
       " u'taste sweet nice better texture bad buds different doesn strong bars green smell chewy tried positives drink wonderful bitter sour',\n",
       " u'flavor heat favorite nice strong texture adds vanilla add perfect licorice sweet rich original amazing gives lemon unique jelly wonderful',\n",
       " u'like don tastes did tasted didn try doesn real feel know strong looks thing flavors jelly drink things want ll',\n",
       " u'chocolate bars bar protein dark eat delicious energy milk snack power peanut butter cookies cream ice box green sweet chocolates',\n",
       " u'love fell friends yummy green products jelly perfect ll hate happy absolutely ones snack chai family flavors kids wish don',\n",
       " u'colors cake color icing black coloring frosting red make wilton gel used set needed birthday food cakes perfect bright easy',\n",
       " u'34 bottle bought say purchased said pure fine gummy need small delivery extract states don chili chips experience strong spice',\n",
       " u'gum chewing orbit long chew bubble lasts mint teeth hard pack mouth time favorite breath lot cinnamon stale gums fresh',\n",
       " u'sauce heat bottle dave pepper sauces spicy bbq food hottest vinegar ghost peppers insanity death tabasco chili chipotle drop jolokia',\n",
       " u'oil olive little garlic cooking add salad salads delicious oils bread butter olives stir fry vinegar extra italy wonderful italian',\n",
       " u'recommend highly wonderful excellent definitely recommended delicious friends favorite amazing buying tasted likes wants meal family absolutely quality looking seller',\n",
       " u'stuff eat bottle time think ice cream long food little drops way got awesome away pretty careful kid better going',\n",
       " u'buy price store amazon local grocery stores bought shipping better online worth cheaper bulk brand able buying cost happy available',\n",
       " u'gift loved bought loves christmas friend said gave got husband sent son family birthday daughter perfect enjoyed year purchased recipient',\n",
       " u'order time ordered arrived fresh amazon received delicious shipping company ordering long item thank delivery place days lobster fast did',\n",
       " u'candy party kids bag lego hard birthday candies pieces eat loved bags box eating blocks build themed little hit fun',\n",
       " u'filters filter cup maker size melitta stores cone hard 12 fit single work grounds case 40 boxes box amazon decker',\n",
       " u'really try spicy enjoy liked food tasty need enjoyed don sweet say nice think know got doesn sure probably things',\n",
       " u'use seasoning chicken make spice salt fish easy used jerky meat add magic cook curry spices dishes paul beef makes',\n",
       " u'tree bonsai leaves arrived plant condition came looks packed box little healthy pot soil packaged trees looked picture care water']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TT.topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.9862853085127044,\n",
       " 0.5173503443757308,\n",
       " 0.48502411883062679,\n",
       " 0.35538087727255796,\n",
       " 0.34567338922562668,\n",
       " 0.19113426763161073,\n",
       " 0.18341024235557535,\n",
       " 0.18333627630265809,\n",
       " 0.18213302629732886,\n",
       " 0.16245170090344285,\n",
       " 0.14397476395917458,\n",
       " 0.13285982848969621,\n",
       " 0.12956828288270855,\n",
       " 0.124436770887781,\n",
       " 0.12335532911892066,\n",
       " 0.12062270619994774,\n",
       " 0.11494182324577067,\n",
       " 0.10842787850542597,\n",
       " 0.10621824238759471,\n",
       " 0.10377771532244993]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TT.topic_weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
